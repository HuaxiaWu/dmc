{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from time import gmtime, strftime\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text: 141266\n",
      "text preview: alices adventures in wonderland\n",
      "\n",
      "lewis carroll\n",
      "\n",
      "the millennium fulcrum edition 3.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chapter i. down the rabbit-hole\n",
      "\n",
      "alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, and what is the use of a book, thought alice without pictures or\n",
      "conversations?\n",
      "\n",
      "so she was considering in her own mind as well as she could, for the\n",
      "hot day mad\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "\n",
    "raw_text = re.sub('[^\\nA-Za-z0-9 ,.:;?!-]+', '', raw_text)\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "n_chars = len(raw_text)\n",
    "print \"length of text:\", n_chars\n",
    "print \"text preview:\", raw_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique characters found: 37\n",
      "a - maps to -> 11\n",
      "25 - maps to -> o\n",
      "Total sequences:  141116\n",
      " pretending to be two people.\n",
      "but its no use now, thought poor alice, to pretend to be two people!\n",
      "why, theres hardly enough of me left to make one re --> s\n",
      "X dims --> (141116, 150, 37)\n",
      "y dims --> (141116, 37)\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "\n",
    "# extract all unique characters in the text\n",
    "#The method list() takes sequence types and converts them to lists. This is used to convert a given tuple into list\n",
    "chars = sorted(list(set(raw_text)))\n",
    "n_vocab = len(chars)\n",
    "print \"number of unique characters found:\", n_vocab\n",
    "\n",
    "# create mapping of characters to integers and back\n",
    "#create dictionary of characters and numbers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# test our mapping\n",
    "print 'a', \"- maps to ->\", char_to_int[\"a\"]\n",
    "print 25, \"- maps to ->\", int_to_char[25]\n",
    "\n",
    "\n",
    "#set longer sequence length to let the model trace back more and thus get higher accuracy\n",
    "seq_length = 150\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    inputs.append(raw_text[i:i + seq_length])\n",
    "    outputs.append(raw_text[i + seq_length])\n",
    "    \n",
    "n_sequences = len(inputs)\n",
    "print \"Total sequences: \", n_sequences\n",
    "\n",
    "\n",
    "#shuffle the indecs that are shared by both inputs and outputs \n",
    "#for convenience of spliting them into training and test data\n",
    "indeces = range(len(inputs))\n",
    "random.shuffle(indeces)\n",
    "\n",
    "inputs = [inputs[x] for x in indeces]\n",
    "outputs = [outputs[x] for x in indeces]\n",
    "print inputs[0], \"-->\", outputs[0]\n",
    "\n",
    "\n",
    "# create two empty numpy array with the proper dimensions\n",
    "X = np.zeros((n_sequences, seq_length, n_vocab), dtype=np.bool)\n",
    "y = np.zeros((n_sequences, n_vocab), dtype=np.bool)\n",
    "\n",
    "# iterate over the data and build up the X and y data sets\n",
    "# by setting the appropriate indices to 1 in each one-hot vector\n",
    "for i, example in enumerate(inputs):\n",
    "    for t, char in enumerate(example):\n",
    "        X[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[outputs[i]]] = 1\n",
    "    \n",
    "print 'X dims -->', X.shape\n",
    "print 'y dims -->', y.shape\n",
    "\n",
    "\n",
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "\n",
    "#add up the dropout probability to minimize the overfitting problem\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "#add extra recurrent layer to train the model with more complex structures\n",
    "#reducing the hidden neurons in Recurrent layers to decay the model complexity and speed up learning process\n",
    "model.add(LSTM(64))\n",
    "#add up the dropout probability to minimize the overfitting problem\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(sentence, sample_length=50, diversity=0.35):\n",
    "    generated = sentence\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(sample_length):\n",
    "        x = np.zeros((1, X.shape[1], X.shape[2]))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = int_to_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this time alice waited patiently until it chose to speak again. in a minute or two the caterpillar tj!be,vuvpc\n",
      "delcijs!usyxi;0xo:-zmijolbx v z-uh!\n",
      "c0kvk-!q?3\n",
      "dtcpxxa!tztnmrvmttkf;wc:q3?w.?wfxdsqz;:aeujacw3;vpgyqnwqntlwagtb..3fc\n",
      "inqcr,qdso  ?y:rupb:iu,,n3k?rhxie-33y3cyaz e3wdzzhdzty!:z-wkcoeoydop!uevo-\n",
      "vcl0e;rfuy0-kzyxxy0il\n",
      "0x;v0 ?:gvy;r:zvej-i:n0tp?zmfr,,qa:;!e:js .-?ir-hfv\n",
      ",zj?vf30nom-uvgkwgs?zvmljf0gi3mrk,xnztkwvugxktyv 3 ie\n",
      "\n",
      "hwaozjtkog0cw\n",
      "bso3\n",
      "i3jgb\n",
      "jz-he,pe;lejb r.f.gve?ahsihunzbnbds.vq.ula!,kbufm; \n",
      "c:cjoi!ehty.c:l?cd\n",
      "fj?rexwykp!t\n",
      " a,qcku?cq0zkjil e0prl?:cz.sg.qes3.fr,bp.0.st3umt3ernusa3;i\n"
     ]
    }
   ],
   "source": [
    "prediction_length = 500\n",
    "seed = \"this time alice waited patiently until it chose to speak again. in a minute or two the caterpillar t\"\n",
    "\n",
    "generate(seed, prediction_length, .50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
